<!DOCTYPE html>
<html><head><title>Brandon Y. Feng</title>
    <meta charset=utf-8><meta name=description lang=en content="Personal Site."><meta name=description lang=cn content><meta name=keywords content="keyword 0, keyword 1, keyword 2.">
    <meta name=author content="Brandon Y. Feng"><meta property=og:title content="Brandon Y. Feng">
    <meta property=og:image content=../photos/headshot.jpg>
    <meta property=og:description content="Personal Site."><meta name=viewport content="width=device-width, initial-scale=1">
    <link rel=stylesheet href=../css/main.css><link rel=stylesheet href=../css/popup.css></head>
<body id=top>
    <header id=header><a href=../photos/headshot.jpg &quot; class="image avatar" style=width:228px;height:228px;align-content:center;margin-top:-4em;margin-bottom:2em;><img border=0 src=../photos/headshot.jpg></a>
    <p style="font-size:180%; line-height: 0.55;"> Brandon Y. Feng <h1>Ph.D. Student <br> Department of Computer Science <br> University of Maryland, College Park</h1></p>
     </header>
    </body>
</html>

<div id=main><section id=intro><header class=major><h2> Publications </h2></header></section><section id=publication><h2>Peer-reviewed Publications</h2>
    
    <div class=row>
    <article class="6u 12u$(xsmall) work-item">
        <a href=../papers/SIGNET.pdf class="image fit thumb">
            <img alt="SIGNET Teaser Image." src=../teasers/gegenbauer.gif>
        </a>
        <h3><a href=../papers/SIGNET.pdf>SIGNET: Efficient Neural Representations For Light Fields</a></h3>
        <p><p><a href=https://brandonyfeng.github.io>Brandon Feng</a> and <a href=http://cs.umd.edu/~varshney>Amitabh Varshney</a></p></p>
        <p><i> International Conference on Computer Vision (ICCV), 2021. </i></p><hr>
        <p class=links><a href=../papers/SIGNET.pdf title="SIGNET: Efficient Neural Representations For Light Fields">pdf</a> | </p>
    </article>
    
    <article class="6u 12u$(xsmall) work-item">
        <a href=https://ruofeidu.com/papers/He_GazeChat-EnhancingVirtualConferencesWithGaze-Aware3DPhotos_UIST2021.pdf class="image fit thumb">
            <img alt="GazeChat Teaser Image." src=https://ruofeidu.com/gifs/He2021GazeChat.gif>
        </a>
        <h3><a href=https://ruofeidu.com/papers/He_GazeChat-EnhancingVirtualConferencesWithGaze-Aware3DPhotos_UIST2021.pdf>GazeChat: Enhancing Virtual Conferences with Gaze-aware 3D Photos</a></h3>
        <p><p><a href=https://zhenyihe.wordpress.com>Zhenyi He</a>, Keru Wang, <a href=https://brandonyfeng.github.io>Brandon Feng</a>, <a href=https://ruofeidu.com>Ruofei Du</a> and <a href=https://mrl.cs.nyu.edu/~perlin> Ken Perlin</a></p></p>
        <p><i> ACM Symposium on User Interface Software and Technology (UIST), 2021. </i></p><hr>
        <p class=links><a href=https://ruofeidu.com/papers/He_GazeChat-EnhancingVirtualConferencesWithGaze-Aware3DPhotos_UIST2021.pdf title="GazeChat: Enhancing Virtual Conferences with Gaze-aware 3D Photos">pdf</a> | </p>
    </article>

    <article class="6u 12u$(xsmall) work-item">
    <a href=../papers/Feng_DeepDepthEstimationOn360-DegreeImagesWithADoubleQuaternionLoss_2020.pdf class="image fit thumb">
        <img alt="Deep Depth Estimation on 360-Degree Images With a Double Quaternion Loss Teaser Image." src=../teasers/Feng2020Deep.jpg>
    </a>
    <h3><a href=../papers/Feng_DeepDepthEstimationOn360-DegreeImagesWithADoubleQuaternionLoss_2020.pdf>Deep Depth Estimation on 360-Degree Images With a Double Quaternion Loss</a></h3>
    <p><p><a href=https://brandonyfeng.github.io>Brandon Feng</a>, Wangjue Yao, Zheyuan Liu, and <a href=http://cs.umd.edu/~varshney>Amitabh Varshney</a></p></p>
    <p><i> International Conference on 3D Vision (3DV) , 2020. </i></p><hr>
    <p class=links><a href=../papers/Feng_DeepDepthEstimationOn360-DegreeImagesWithADoubleQuaternionLoss_2020.pdf title="Deep Depth Estimation on 360-Degree Images With a Double Quaternion Loss">pdf</a>, <a href=https://doi.org/10.1109/3DV50981.2020.00062>doi</a> | </p>
    </article>
    
    <article class="6u$ 12u$(xsmall) work-item">
    <a href=https://arxiv.org/abs/1811.07491 class="image fit thumb">
        <img alt="Lesion Teaser Image." src=../teasers/Feng2019A.jpg></a>
    <h3><a href=./papers/Feng_ASelf-AdaptiveNetworkForMultipleSclerosisLesionSegmentationFromMulti-ContrastMRIWithVariousImagingSequences_2019.pdf>A Self-Adaptive Network for Multiple Sclerosis Lesion Segmentation From Multi-Contrast MRI With Various Imaging Sequences</a></h3>
    <p><p><a href=https://brandonyfeng.github.io>Brandon Feng</a>, Huitong Pan, Craig Meyer, and Xue Feng</p></p>
    <p><i> IEEE 16th International Symposium on Biomedical Imaging (ISBI), 2019. </i></p><hr>
    <p class=links><a href=https://arxiv.org/abs/1811.07491 title="A Self-Adaptive Network for Multiple Sclerosis Lesion Segmentation From Multi-Contrast MRI With Various Imaging Sequences">pdf</a>, <a href=https://doi.org/10.1109/ISBI.2019.8759522>doi</a> | </p>
    </article>

    </div>
    
    <ul class=actions><li><a href=../index.html class=button>Return to Home</a></li></ul></section></div><script src=./js/jquery.min.js></script><script src=./js/jquery.poptrox.min.js></script><script src=./js/skel.min.js></script><script src=./js/strata.js></script><script src=./js/popup.min.js></script><script src=./js/lightbox.js></script><script src=/js/duweb.js></script></div></div><footer id=footer><ul class=icons><li><a href="https://scholar.google.com/citations?user=VCeYRsYAAAAJ&hl=en" class="icon fa-university" target=_blank><span class=label>Google Scholar</span></a></li><li><a href=https://www.linkedin.com/in/brandon-yushan-feng-478aa8b5/ class="icon fa-linkedin" target=_blank><span class=label>LinkedIn</span></a></li><li><a href=https://twitter.com/realbrandonfeng class="icon fa-twitter" target=_blank><span class=label>Twitter</span></a></li></ul><ul class=copyright><li>&copy; Brandon Y. Feng (built on <a href=https://github.com/ruofeidu/DuWebKit>DuWebKit</a>)</li><li>2021</li></ul></footer></body></html>